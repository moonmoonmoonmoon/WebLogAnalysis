# Distributed Web Log Analysis with Anomaly Detection

A PySpark-based system for analyzing large-scale web server logs and detecting traffic anomalies in real-time.

## ğŸ¯ Features

- **Distributed Log Parsing**: Process millions of log entries using Apache Spark
- **Real-time Analytics**: Compute traffic statistics (top URLs, IPs, status codes)
- **Anomaly Detection**: Identify suspicious traffic patterns including DDoS attacks
- **Visualization**: Generate professional charts and reports
- **Synthetic Data**: Built-in log generator for testing and development

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Apache Spark 3.x
- Java 8 or 11

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/WebLogAnalysis.git
cd WebLogAnalysis

# Install dependencies
pip install pyspark matplotlib seaborn pandas
```

### Usage

```bash
# Generate sample logs
python log_generator.py

# Run complete demo
python milestone_demo.py

# Or run quick test
python quick_test.py
```

## ğŸ“Š Performance

- **Processing Speed**: 17,000+ entries/second
- **Scalability**: Handles datasets from MB to GB scale
- **Efficiency**: Processes 80K logs in under 5 seconds

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Web Server Logs                â”‚
â”‚   (Apache/Nginx format)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    PySpark Log Parser               â”‚
â”‚  (Regex-based extraction)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Distributed Processing            â”‚
â”‚  â€¢ Analytics  â€¢ Aggregation         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Analytics  â”‚  â”‚   Anomaly    â”‚
â”‚  â€¢ Top URLs â”‚  â”‚   Detection  â”‚
â”‚  â€¢ Top IPs  â”‚  â”‚  â€¢ High Vol  â”‚
â”‚  â€¢ Status   â”‚  â”‚  â€¢ Errors    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
WebLogAnalysis/
â”œâ”€â”€ web_log_analyzer.py      # Main analysis engine
â”œâ”€â”€ log_generator.py         # Synthetic log generator
â”œâ”€â”€ visualizations.py        # Chart generation
â”œâ”€â”€ milestone_demo.py        # Complete demo
â”œâ”€â”€ quick_test.py           # Quick functionality test
â””â”€â”€ sample_logs/            # Sample datasets
    â”œâ”€â”€ web_10mb.log
    â””â”€â”€ web_mixed.log
```

## ğŸ” Analysis Capabilities

### Basic Analytics
- Top-N URLs by request count
- Top-N IPs by request count
- HTTP status code distribution
- Traffic volume over time

### Anomaly Detection
- **High-Volume IPs**: Detects potential DDoS sources
- **Error Rate Surge**: Identifies attack patterns (100% error rate)
- **Configurable Thresholds**: Adjust sensitivity based on requirements

### Example Output
```
Top 10 Anomalous IPs:
  4.8.41.25        â†’ 214 requests, 100% error rate
  214.3.198.102    â†’ 208 requests, 100% error rate
  77.124.250.162   â†’ 205 requests, 100% error rate
```

## ğŸ“ˆ Visualization

The system generates publication-quality charts:
- HTTP Status Distribution (Pie Chart)
- Top URLs/IPs (Bar Chart)
- Performance Analysis (Line/Bar Chart)
- Anomalous Traffic Tables

## ğŸ§ª Testing

```bash
# Generate test data
python log_generator.py

# Run tests
python quick_test.py
```

**Test Results:**
- âœ… Log Parser: 2.3s for 50K entries
- âœ… Analytics: 1.5s
- âœ… Anomaly Detection: 0.8s

## ğŸ› ï¸ Technology Stack

- **Apache Spark**: Distributed data processing
- **PySpark**: Python API for Spark
- **Matplotlib/Seaborn**: Data visualization
- **Pandas**: Data manipulation
- **Python 3.8+**: Core language

## ğŸ“– API Example

```python
from web_log_analyzer import WebLogAnalyzer

# Initialize
analyzer = WebLogAnalyzer("MyAnalysis")

# Parse logs
df = analyzer.parse_apache_log('logs/*.log')

# Compute statistics
stats = analyzer.compute_basic_statistics()

# Detect anomalies
anomalies = analyzer.detect_anomalies(
    ip_threshold=100,
    error_rate_threshold=0.3
)

# Clean up
analyzer.stop()
```

## ğŸ”§ Configuration

### Anomaly Detection Thresholds

```python
# In web_log_analyzer.py
anomalies = analyzer.detect_anomalies(
    ip_threshold=100,        # Min requests to flag high-volume
    error_rate_threshold=0.3 # Min error rate (30%) to flag suspicious
)
```

### Log Generator Parameters

```python
# In log_generator.py
generator.generate_mixed_traffic(
    output_file="log_file.log",
    num_requests=50000,
    error_rate=0.8,
    duration_hours=2,
    attack_duration_hours=0.333,
)
```

## ğŸ“Š Sample Datasets

Included synthetic datasets:
- **web_10mb.log**: 50K normal traffic entries (4.4 MB)
- **web_mixed.log**: 30K mixed traffic with simulated DDoS (2.6 MB)

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:
- Report bugs
- Suggest features
- Submit pull requests

## ğŸ“„ License

MIT License

## ğŸ‘¥ Authors

- Weidong Wang
- Yanan Zhang
- Yuxin Sun
- Zhehuan Chen

## ğŸ”— Links

- Course: Systems for Data Science
- Institution: UMass Amherst

---

**Note**: This project was developed as part of a graduate-level data science course focusing on distributed systems and large-scale data processing.
